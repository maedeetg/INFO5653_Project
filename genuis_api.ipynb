{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f8a401d-799d-4882-82a1-ea380231df77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import nltk\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from bs4 import BeautifulSoup \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7ae734d-4b5b-455e-b5eb-2796704965fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id = \"yxeLnXDdwoDJunEPDRUgYVmH-I703sGZKWGoCdKbFNupYKHugalkOVqtzh3aSe82\"\n",
    "client_secret = \"zd3utRAeYAprwImrgEPERa6BPjNrJMOcg4ogsbTAR-uCoIoh9zu28ufhMVRYlBTpb8kSHkWK75LDrHSerdEOag\"\n",
    "client_access_token = \"wVsdPF-_vbLLypQZ3qaR0EwytwJW2jKBsK-PoZwv6BDKQLDK0gkUwstOYuH-EDD2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01a8e157-809a-4650-b8b9-28a5b2a6159c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_song_info(artist_name, song_title):\n",
    "    base_url = 'https://api.genius.com'\n",
    "    headers = {'Authorization': f'Bearer {client_access_token}'}\n",
    "    search_url = base_url + '/search'\n",
    "    params = {'q': f'{artist_name} {song_title}'}\n",
    "\n",
    "    response = requests.get(search_url, params = params, headers = headers)\n",
    "    return response\n",
    "\n",
    "def request_song_url(artist_name, song_titles):\n",
    "    # Input is song titles, want to find associated urls with each\n",
    "    urls = []\n",
    "    track_names = []\n",
    "\n",
    "    for song in song_titles:\n",
    "        #print(song)\n",
    "        song = re.sub(\"´\", \"'\", song)\n",
    "        song = re.sub(\"  \", \" \", song)\n",
    "        response = request_song_info(artist_name, song)\n",
    "        json = response.json()\n",
    "    \n",
    "        # Extract the first matching song URL\n",
    "        hit = json['response']['hits'][0]['result']\n",
    "        #print(hit)\n",
    "        #print(hit['title'].lower())\n",
    "        if (artist_name.lower() in hit['primary_artist']['name'].lower()):\n",
    "            song_url = hit['url']\n",
    "            urls.append(song_url)\n",
    "            \n",
    "            match = re.search(r'beatles-(.*?)-lyrics', song_url)\n",
    "    \n",
    "            if match:\n",
    "                result = match.group(1) \n",
    "                track_names.append(result)\n",
    "        \n",
    "    # Return both the URL and the song title\n",
    "    return [urls, track_names] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "90f73abc-c541-4d8f-8514-fa83d79675a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First want to only have songs that are composed by lennon or mccartney\n",
    "os.chdir(\"C:/Users/maede/Downloads/Python/INFO5653/Project/Project/INFO5653_Project\")\n",
    "df = pd.read_csv(\"song_composer_singer.csv\")\n",
    "df.columns = [\"Song\", \"Composer\", \"Singer\"]\n",
    "lennon_mccartney = df[df['Composer'].isin([\"Lennon\", \"McCartney\"])]\n",
    "\n",
    "# Now want to match songs from this set to the lyrics pulled from genuis api\n",
    "l_m_songs = list(lennon_mccartney['Song'])\n",
    "\n",
    "# Composer list\n",
    "l_m_composer = list(lennon_mccartney['Composer'])\n",
    "\n",
    "# Find urls!\n",
    "artist_name = \"The Beatles\"\n",
    "[urls, song_titles] = request_song_url(artist_name, l_m_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0d9e9680-0527-4d6f-9691-4719b3a5e74d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(song_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "16743177-e618-4f4a-8f0a-e227dda4b441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape lyrics from a Genius.com song URL\n",
    "def scrape_song_lyrics(url):\n",
    "    song = requests.get(url)\n",
    "    html = BeautifulSoup(song.content, 'html.parser')\n",
    "    lyrics_divs = html.find_all(\"div\", {\"data-lyrics-container\": \"true\"})\n",
    "    \n",
    "    if lyrics_divs:\n",
    "        lyrics = \"\\n\".join(div.get_text(separator=\"\\n\") for div in lyrics_divs)\n",
    "        # Remove identifiers like chorus, verse, etc\n",
    "        lyrics = re.sub(r'[\\(\\[].*?[\\)\\]]', '', lyrics, flags=re.DOTALL).strip()\n",
    "        \n",
    "        # Remove empty lines\n",
    "        lyrics = os.linesep.join([s for s in lyrics.splitlines() if s])  \n",
    "    else:\n",
    "        print(\"Lyrics not found!\")\n",
    "        lyrics = \"\"\n",
    "    \n",
    "    return lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "745c4d5c-c858-4ef7-b958-eab1a5a48b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_lyrics_to_corpus(urls, track_names, composer, path):\n",
    "    for i in range(len(track_names)):\n",
    "        # Get url and title\n",
    "        url = urls[i]\n",
    "        title = track_names[i]\n",
    "        label = composer[i]\n",
    "        title = re.sub(\" \", \"-\", title)\n",
    "        title = re.sub(r\"\\?\", \"\", title)\n",
    "        title = title.lower()\n",
    "    \n",
    "        # Create file, mypath, and filename\n",
    "        file = str(label) + '-' + str(title) + \".txt\"\n",
    "        filename = mypath + \"/\" + file\n",
    "    \n",
    "        # Open file to write to\n",
    "        my_file = open(filename, \"w\", encoding = \"utf-8\")\n",
    "    \n",
    "        # Find lyrics\n",
    "        lyrics = scrape_song_lyrics(url)\n",
    "        my_file.write(lyrics)\n",
    "        my_file.close()\n",
    "\n",
    "mypath = \"C:/Users/maede/Downloads/Python/INFO5653/Project/Project/INFO5653_Project/Composer_Lyrics_Corpus\"\n",
    "write_lyrics_to_corpus(urls, song_titles, l_m_composer, mypath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "98477c2d-3473-4ddf-a495-83ad7cbb9ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## PART 3: USE CORPUS TO BUILD DATAFRAME ##########\n",
    "\n",
    "# Path to corpus\n",
    "path = \"C:/Users/maede/Downloads/Python/INFO5653/Project/Project/INFO5653_Project/Composer_Lyrics_Corpus\"\n",
    "\n",
    "# Create file name\n",
    "file_name_list = os.listdir(path)\n",
    "\n",
    "# Initliaze empty lists that will be filled later with all file paths in corpus\n",
    "complete_file_paths = [] \n",
    "list_file_names = []\n",
    "    \n",
    "for name in file_name_list:\n",
    "    nextfile = path + \"/\" + name \n",
    "    complete_file_paths.append(nextfile) \n",
    "    nextnameL = name.split(\".\")\n",
    "    list_file_names.append(nextnameL[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b60b3511-ef04-41ba-96be-55a75be83e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new file that will be written later. \n",
    "filename = \"composer_lyrics.csv\"\n",
    "\n",
    "# Open file \n",
    "my_file = open(filename, \"w\", encoding=\"utf-8\")\n",
    "\n",
    "# Write column names in first row\n",
    "write_this = \"Composer,Lyrics\\n\"\n",
    "my_file.write(write_this)\n",
    "my_file.close()\n",
    "\n",
    "# Open file for appending to\n",
    "my_file = open(filename, \"a\", encoding = \"utf-8\")\n",
    "\n",
    "# Read each file and store contents\n",
    "for file_path in complete_file_paths:\n",
    "    # Find label\n",
    "    if \"McCartney\" in file_path:\n",
    "        label = \"McCartney\"\n",
    "    if \"Lennon\" in file_path:\n",
    "        label = \"Lennon\"\n",
    "        \n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        content = file.read()\n",
    "        content = re.sub(r'[,.;@#?!&$\\-\\']+', ' ', content, flags = re.IGNORECASE)\n",
    "        content = re.sub(' +', ' ', content, flags = re.IGNORECASE)\n",
    "        content = re.sub(r'\\\"', ' ', content, flags = re.IGNORECASE)\n",
    "        content = re.sub(r'[^a-zA-Z]', \" \", content, flags = re.VERBOSE)\n",
    "        content = content.replace(',', '')\n",
    "        content = ' '.join(content.split())\n",
    "        content = re.sub(\"\\n|\\r\", \" \", content)\n",
    "        \n",
    "        write_this = str(label) + \",\" + str(content) + \"\\n\"\n",
    "        my_file.write(write_this)\n",
    "my_file.close()                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f7eae036-c66e-4c9f-a3b3-c2e51d72af38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Composer</th>\n",
       "      <th>Lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lennon</td>\n",
       "      <td>It s been a hard day s night And I ve been wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lennon</td>\n",
       "      <td>Words are flowing out like endless rain into a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lennon</td>\n",
       "      <td>Whenever I want you around yeah All I got to d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lennon</td>\n",
       "      <td>Love love love Love love love Love love love T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lennon</td>\n",
       "      <td>Tell me that you ve got everything you want An...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>McCartney</td>\n",
       "      <td>In the town where I was born Lived a man who s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>McCartney</td>\n",
       "      <td>Yesterday All my troubles seemed so far away N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>McCartney</td>\n",
       "      <td>You never give me your money You only give me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>McCartney</td>\n",
       "      <td>When I call you up Your line s engaged I have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>McCartney</td>\n",
       "      <td>Let s all get up and dance to a song That was ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Composer                                             Lyrics\n",
       "0       Lennon  It s been a hard day s night And I ve been wor...\n",
       "1       Lennon  Words are flowing out like endless rain into a...\n",
       "2       Lennon  Whenever I want you around yeah All I got to d...\n",
       "3       Lennon  Love love love Love love love Love love love T...\n",
       "4       Lennon  Tell me that you ve got everything you want An...\n",
       "..         ...                                                ...\n",
       "136  McCartney  In the town where I was born Lived a man who s...\n",
       "137  McCartney  Yesterday All my troubles seemed so far away N...\n",
       "138  McCartney  You never give me your money You only give me ...\n",
       "139  McCartney  When I call you up Your line s engaged I have ...\n",
       "140  McCartney  Let s all get up and dance to a song That was ...\n",
       "\n",
       "[141 rows x 2 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(filename)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fed959ee-1530-427a-87ae-9d170192259b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE COUNTVECTORIZOR AND LET MAX_FEATURES = 100\n",
    "\n",
    "# Now we can use CountVectorizer \n",
    "my_vect = CountVectorizer(input = 'filename', stop_words = 'english', token_pattern=r'\\b[a-zA-Z]{4,}\\b', max_features = 100)\n",
    "fit = my_vect.fit_transform(complete_file_paths)\n",
    "column_names = my_vect.get_feature_names_out()\n",
    "\n",
    "# Convert to dataframe\n",
    "lyrics_df = pd.DataFrame(fit.toarray(),columns = column_names)\n",
    "\n",
    "# Add labels using a dictionary\n",
    "dict_labels = {}\n",
    "\n",
    "for i in range(0, len(complete_file_paths)):\n",
    "    dict_labels[i] = list_file_names[i].split(\"-\")[0]\n",
    "\n",
    "lyrics_df = lyrics_df.rename(dict_labels, axis = \"index\")\n",
    "lyrics_df.index.name = \"LABEL\"\n",
    "\n",
    "# Write dataframe to csv\n",
    "lyrics_df.to_csv(\"paul_john_lyrics_corpus_count100.csv\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0061c7ce-8891-498d-930a-a146c5cfff10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maede\\New folder\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# LEMMING, CountVectorizer, max_features = 100\n",
    "LEMMER = WordNetLemmatizer() \n",
    "\n",
    "def MY_LEMMER(str_input):\n",
    "    words = re.sub(r\"[^A-Za-z\\-]\", \" \", str_input).lower().split()\n",
    "    words = [LEMMER.lemmatize(word) for word in words]\n",
    "    return words\n",
    "    \n",
    "my_vect = CountVectorizer(input = 'filename', tokenizer = MY_LEMMER, max_features = 100)\n",
    "fit = my_vect.fit_transform(complete_file_paths)\n",
    "column_names = my_vect.get_feature_names_out()\n",
    "\n",
    "# Convert to dataframe\n",
    "lyrics_df = pd.DataFrame(fit.toarray(),columns = column_names)\n",
    "\n",
    "# Add labels using a dictionary\n",
    "dict_labels = {}\n",
    "\n",
    "for i in range(0, len(complete_file_paths)):\n",
    "    dict_labels[i] = list_file_names[i].split(\"-\")[0]\n",
    "\n",
    "lyrics_df = lyrics_df.rename(dict_labels, axis = \"index\")\n",
    "lyrics_df.index.name = \"Label\"\n",
    "\n",
    "# Write dataframe to csv\n",
    "lyrics_df.to_csv(\"paul_john_lyrics_corpus_lem_count100.csv\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6ebb083-62f4-4cf3-927a-28a72b912ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maede\\New folder\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# STEMMING, CountVectorizer, max_features = 100\n",
    "STEMMER = PorterStemmer()\n",
    "def MY_STEMMER(str_input):\n",
    "    words = re.sub(r\"[^A-Za-z\\-]\", \" \", str_input).lower().split()\n",
    "    words = [STEMMER.stem(word) for word in words]\n",
    "    return words\n",
    "    \n",
    "my_vect = CountVectorizer(input = 'filename', tokenizer = MY_STEMMER, max_features = 100)\n",
    "fit = my_vect.fit_transform(complete_file_paths)\n",
    "column_names = my_vect.get_feature_names_out()\n",
    "\n",
    "# Convert to dataframe\n",
    "lyrics_df = pd.DataFrame(fit.toarray(),columns = column_names)\n",
    "\n",
    "# Add labels using a dictionary\n",
    "dict_labels = {}\n",
    "\n",
    "for i in range(0, len(complete_file_paths)):\n",
    "    dict_labels[i] = list_file_names[i].split(\"-\")[0]\n",
    "\n",
    "lyrics_df = lyrics_df.rename(dict_labels, axis = \"index\")\n",
    "lyrics_df.index.name = \"Label\"\n",
    "\n",
    "# Write dataframe to csv\n",
    "lyrics_df.to_csv(\"paul_john_lyrics_corpus_stem_count100.csv\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa8b7b9-d652-402c-ba8e-1bd5e5933ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
