{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af98e8b7-f11c-4c1a-9cb7-d0884c60acfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import wordcloud\n",
    "import re\n",
    "import os\n",
    "\n",
    "from bs4 import BeautifulSoup \n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88dcbdc6-257a-4d26-85be-bc546fe343da",
   "metadata": {},
   "outputs": [],
   "source": [
    "### First website that I am scraping. This website has all beatles songs, \n",
    "# who wrote them, and who sang them\n",
    "\n",
    "def get_rid(words, clean = None):\n",
    "    # Need this so we do not reset clean at each recursion\n",
    "    if clean is None:\n",
    "        clean = [] \n",
    "\n",
    "    for i in range(len(words)):\n",
    "        if \"total\" in words[i].lower():\n",
    "            j = i\n",
    "            continue\n",
    "        if \"singer\" in words[i].lower():\n",
    "            k = i\n",
    "            keep1 = words[:j]\n",
    "            keep2 = words[i+1:]\n",
    "            clean.extend(keep1)\n",
    "\n",
    "            return get_rid(keep2, clean = clean)\n",
    "    return clean \n",
    "\n",
    "## Get the data\n",
    "url = \"https://www.myrsten.nu/worldnet/beatlesongs.htm\"\n",
    "res = requests.get(url)\n",
    "htmlData = res.content\n",
    "\n",
    "## Parse the Data\n",
    "soup = BeautifulSoup(htmlData, \"html.parser\")\n",
    "\n",
    "# Find all <td> elements\n",
    "td_elements = soup.find_all(\"td\")\n",
    "\n",
    "# We want to store song, composer, and singer. \n",
    "songs = []\n",
    "\n",
    "# Skip headers, then process title, composer, and singer\n",
    "td_texts = [td.get_text(strip=True) for td in td_elements[4:]]  # Skip headers\n",
    "#print(td_texts)\n",
    "\n",
    "# One part where the text is a different langauge, change that\n",
    "index1 = td_texts.index(\"Låt\")\n",
    "index2 = td_texts.index(\"Huvudkompositör\")\n",
    "index3 = td_texts.index(\"Sångare\")\n",
    "\n",
    "td_texts[index1] = \"Song\"\n",
    "td_texts[index2] = \"Main composer\"\n",
    "td_texts[index3] = \"Singer\"\n",
    "\n",
    "# There is some text that we want to remove before saving song_title, composer, and singer\n",
    "clean = get_rid(td_texts)\n",
    "\n",
    "for i in range(0, len(clean), 3):\n",
    "    if i + 2 < len(clean):\n",
    "        song_title = clean[i]\n",
    "        #print(song_title)\n",
    "        composer = clean[i + 1]\n",
    "        singer = clean[i + 2]\n",
    "\n",
    "        # Some cleaning\n",
    "        song_title = song_title.replace(\"\\n\", \" \")\n",
    "        composer = composer.replace(\"\\n\", \" \")\n",
    "        singer = singer.replace(\"\\n\", \" \")\n",
    "        song_title = re.sub(r'\\\"', ' ', song_title, flags = re.IGNORECASE)\n",
    "        composer = re.sub(r'\\\"', ' ', composer, flags = re.IGNORECASE)\n",
    "        singer = re.sub(r'\\\"', ' ', singer, flags = re.IGNORECASE)\n",
    "        song_title = re.sub(r',', ' ', song_title, flags = re.IGNORECASE)\n",
    "        composer = re.sub(r',', ' ', composer, flags = re.IGNORECASE)\n",
    "        singer = re.sub(r',', ' ', singer, flags = re.IGNORECASE)\n",
    "        song_title = re.sub(r'\\d+', '', song_title, flags = re.IGNORECASE)\n",
    "\n",
    "        song_title = song_title.lstrip()\n",
    "        song_title = song_title.rstrip() \n",
    "        song_title = song_title.strip()\n",
    "        composer = composer.lstrip()\n",
    "        composer = composer.rstrip() \n",
    "        composer = composer.strip()\n",
    "        singer = singer.lstrip()\n",
    "        singer = singer.rstrip() \n",
    "        singer = singer.strip()\n",
    "\n",
    "        # if song_title not in [\"\", \"\\\\\", '\"', \"'\", \"*\", \":\", \";\"]:\n",
    "        #     # Remove digits\n",
    "        #     if not re.search(r'\\d', song_title):\n",
    "        #         print('before', song_title)\n",
    "        #         song_title = re.search(r'\\d', song_title)\n",
    "        #         print('after', song_title)\n",
    "\n",
    "\n",
    "        # re.sub(r'\\d+', '', text)\n",
    "        songs.append([song_title, composer, singer])\n",
    "\n",
    "# Write to csv file\n",
    "filename = \"song_composer_singer.csv\"\n",
    "\n",
    "# Open file\n",
    "my_file = open(filename, \"w\", encoding='utf8')\n",
    "\n",
    "# Write first rows, which are column names\n",
    "write_this = \"Song, Composer, Singer \\n\"\n",
    "my_file.write(write_this)\n",
    "my_file.close()\n",
    "\n",
    "my_file = open(filename, \"a\", encoding='utf8')\n",
    "\n",
    "for group in songs:\n",
    "    song = group[0] \n",
    "    composer = group[1]\n",
    "    singer = group[2]\n",
    "\n",
    "    write_this = str(song) + \",\" + str(composer) + \",\" + str(singer) + \"\\n\"\n",
    "    my_file.write(write_this)\n",
    "\n",
    "my_file.close()\n",
    "\n",
    "# First want to only have songs that are composed by lennon or mccartney\n",
    "os.chdir(\"C:/Users/maede/Downloads/Python/INFO5653/Project/Project/INFO5653_Project\")\n",
    "df = pd.read_csv(\"song_composer_singer.csv\", index_col=None)\n",
    "df.columns = [\"Song\", \"Composer\", \"Singer\"]\n",
    "lennon_mccartney = df.loc[df['Composer'].isin([\"Lennon\", \"McCartney\"])]\n",
    "lennon_mccartney.to_csv(\"lennon_mccartney.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "170b75ca-f81b-4302-87ab-09d7b9ea72b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this part, we are looking at song titles as our data.\n",
    "# Open path, create file, open file, write column names, close file\n",
    "path = \"C:/Users/maede/Downloads/Python/INFO5653/Project/Project/INFO5653_Project/lennon_mccartney.csv\"\n",
    "file = open(path,\"r\", encoding=\"utf-8\")\n",
    "filename = \"lennon_mccartney_clean.csv\"\n",
    "new_file = open(filename,\"w\", encoding=\"utf-8\")\n",
    "to_write = \"Label,Song Title\\n\"\n",
    "new_file.write(to_write)\n",
    "new_file.close()\n",
    "\n",
    "# Open file to append to\n",
    "new_file = open(filename, \"a\", encoding=\"utf-8\")\n",
    "\n",
    "# Initliaze empty dataframe\n",
    "tennis_pickleball_clean_df = pd.DataFrame()\n",
    "output_file = \"lennon_mccartney.txt\"\n",
    "outfile = open(output_file,\"w\", encoding=\"utf-8\")\n",
    "outfile.close()\n",
    "outfile = open(output_file,\"a\", encoding=\"utf-8\") \n",
    "\n",
    "# Skip reading in the column names\n",
    "next(file) \n",
    "for row in file:\n",
    "    # Remove any necessary spaces from each row\n",
    "    row = re.sub(r'^\\d+,', '', row)\n",
    "    row = row.lstrip()\n",
    "    row = row.rstrip() \n",
    "    row = row.strip()\n",
    "    \n",
    "    # Split at each space to look at words\n",
    "    words = re.split(\" \", row)\n",
    "    words_clean = []\n",
    "\n",
    "    for word in words:\n",
    "        # Clean words!\n",
    "        word = word.lower() \n",
    "        word = word.lstrip()\n",
    "        # word = word.replace(\",\",\"\") \n",
    "        word = word.replace(\" \",\"\")\n",
    "        word = word.replace(\"_\",\"\" )\n",
    "        word = re.sub('\\+', ' ', word) \n",
    "        word = re.sub('.*\\+\\n', '', word)\n",
    "        word = re.sub('zz+', ' ', word)\n",
    "        word = word.replace(\"\\t\",\"\")\n",
    "        word = word.replace(\".\",\"\")\n",
    "        word = word.strip()\n",
    "        words_clean.append(word)\n",
    "    \n",
    "    #print(words_clean[-1])\n",
    "    last_word = words_clean[-1].split(',')[0]\n",
    "    label = words_clean[-1].split(',')[-2]\n",
    "    words_clean[-1] = last_word\n",
    "    \n",
    "    if \"lennon\" in label:\n",
    "        label = \"john\"\n",
    "    if \"mccartney\" in label:\n",
    "        label = \"paul\"\n",
    "   \n",
    "    #print(label)\n",
    "    \n",
    "    text = \" \".join(words_clean)\n",
    "    \n",
    "    ### More cleaning\n",
    "    text = text.replace(\"\\\\n\",\"\")\n",
    "    text = text.strip(\"\\\\n\")\n",
    "    text = text.replace(\"\\\\'\",\"\")\n",
    "    text = text.replace(\"\\\\\",\"\")\n",
    "    text = text.replace('\"',\"\")\n",
    "    text = text.replace(\"'\",\"\")\n",
    "    text = text.replace(\"s'\",\"\")\n",
    "    text = text.lstrip()\n",
    "    text = text.split(\",\")[-1]\n",
    "\n",
    "    # Write to files\n",
    "    write = label + \",\"+ text + \"\\n\"\n",
    "    new_file.write(write)\n",
    "    outfile.write(write)\n",
    "     \n",
    "# Close files\n",
    "file.close()  \n",
    "new_file.close()\n",
    "outfile.close()\n",
    "\n",
    "# Read in clean csv to use count vectorizor on\n",
    "clean = pd.read_csv(filename)\n",
    "\n",
    "# Some cleaning\n",
    "clean = clean.dropna(how = 'any', axis = 0)  ## axis 0 is rowwise\n",
    "\n",
    "# Store labels\n",
    "labels = clean[\"Label\"]\n",
    "\n",
    "# Store data without labels\n",
    "data = clean.drop([\"Label\"], axis=1) \n",
    "\n",
    "# Build a list of content that countvectorizer expects.\n",
    "my_list = [] \n",
    "\n",
    "for i in range(0, len(data)):\n",
    "    next_text = data.iloc[i,0]\n",
    "    my_list.append(next_text)\n",
    "\n",
    "# Now vectorize\n",
    "my_vect = TfidfVectorizer(input = 'content', stop_words = \"english\", max_features = 50)\n",
    "\n",
    "fit = my_vect.fit_transform(my_list)\n",
    "\n",
    "# Add columns names and labels\n",
    "column_names = my_vect.get_feature_names_out()\n",
    "lennon_mccartney_clean = pd.DataFrame(fit.toarray(), columns = column_names)\n",
    "lennon_mccartney_clean = lennon_mccartney_clean.rename(labels, axis = \"index\")\n",
    "lennon_mccartney_clean.index.name = \"LABEL\"\n",
    "\n",
    "# Write dataframe to csv\n",
    "lennon_mccartney_clean.to_csv(\"lennon_mccartney_clean.csv\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12111192-0718-4ba6-ad36-778107e8cad9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
